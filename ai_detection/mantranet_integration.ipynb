{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63cdf18b",
   "metadata": {},
   "source": [
    "# ManTraNet Integration Plan for Sus Scrofa\n",
    "\n",
    "**ManTra-Net: Manipulation Tracing Network For Detection and Localization of Image Forgeries**\n",
    "\n",
    "This notebook documents the integration of ManTraNet into Sus Scrofa's forensic analysis pipeline.\n",
    "\n",
    "## What is ManTraNet?\n",
    "\n",
    "ManTraNet is a deep learning model that:\n",
    "- **Detects** image manipulations (splicing, copy-move, removal, inpainting)\n",
    "- **Localizes** manipulated regions by generating pixel-level forgery masks\n",
    "- Outputs a heatmap where 0 = pristine, 1 = manipulated\n",
    "- Pre-trained on 385 different manipulation types\n",
    "\n",
    "## Integration Goals\n",
    "\n",
    "1. ✅ Add ManTraNet as a detector in `ai_detection/detectors/`\n",
    "2. ✅ Generate forgery masks and save to GridFS\n",
    "3. ✅ Create audit findings for the auditor based on mask analysis\n",
    "4. ✅ Add a new \"Forgery Localization\" tab in the UI\n",
    "5. ✅ Display forgery masks overlaid on original images\n",
    "\n",
    "## References\n",
    "\n",
    "- **GitHub**: https://github.com/ISICV/ManTraNet\n",
    "- **Colab Demo**: https://colab.research.google.com/drive/1ai4kVlI6w9rREqqYnTfpk3gM3YX9k-Ek\n",
    "- **Paper**: CVPR 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b40e62c",
   "metadata": {},
   "source": [
    "## 2. ManTraNet Architecture Overview\n",
    "\n",
    "Based on the Colab notebook, ManTraNet:\n",
    "\n",
    "### Model Structure\n",
    "- **Input**: RGB image, normalized to [-1, 1]\n",
    "- **Architecture**: VGG-style feature extractor + manipulation tracer\n",
    "- **Output**: Single-channel mask (H×W) with values 0-1\n",
    "  - 0 = pristine pixel\n",
    "  - 1 = manipulated pixel\n",
    "\n",
    "### Inference Process\n",
    "\n",
    "```python\n",
    "# From Colab notebook\n",
    "def decode_an_image_array(rgb, manTraNet, dn=1):\n",
    "    # Normalize to [-1, 1]\n",
    "    x = np.expand_dims(rgb.astype('float32')/255.*2-1, axis=0)\n",
    "    \n",
    "    # Downsample for speed (optional)\n",
    "    x = x[:, ::dn, ::dn]\n",
    "    \n",
    "    # Run inference\n",
    "    y = manTraNet.predict(x)[0, ..., 0]\n",
    "    \n",
    "    return y  # Shape: (H, W), values in [0, 1]\n",
    "```\n",
    "\n",
    "### Model Requirements\n",
    "- TensorFlow 1.14 (original implementation)\n",
    "- Python 3.6\n",
    "- Pre-trained weights (~100MB)\n",
    "- Separate virtual environment recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c4613d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "ManTraNet Detector — Image Manipulation Localization\n",
    "\n",
    "Generates pixel-level forgery masks showing WHERE an image was manipulated.\n",
    "Detects: copy-move, splicing, removal, inpainting, clone stamp, smudge tool.\n",
    "\n",
    "Returns:\n",
    "- Forgery mask (heatmap 0-1)\n",
    "- Audit findings based on mask analysis\n",
    "- Manipulated percentage and region count\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "from typing import Optional\n",
    "import subprocess\n",
    "import json\n",
    "\n",
    "from .base import BaseDetector, DetectionResult, DetectionMethod, ConfidenceLevel\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "class ManTraNetDetector(BaseDetector):\n",
    "    \"\"\"\n",
    "    ManTraNet manipulation localization detector.\n",
    "    \n",
    "    Runs in subprocess using TF 1.14 environment (separate from main app).\n",
    "    Generates forgery masks and creates audit findings based on analysis.\n",
    "    \"\"\"\n",
    "    \n",
    "    def get_order(self) -> int:\n",
    "        \"\"\"Run after AI detection but alongside OpenCV (order ~70).\"\"\"\n",
    "        return 70\n",
    "    \n",
    "    def check_deps(self) -> bool:\n",
    "        \"\"\"Check if ManTraNet model and TF 1.14 environment exist.\"\"\"\n",
    "        try:\n",
    "            mantranet_dir = Path(__file__).parent.parent / \"ManTraNet\"\n",
    "            model_path = mantranet_dir / \"pretrained_weights\"\n",
    "            \n",
    "            if not model_path.exists():\n",
    "                logger.warning(\"ManTraNet model not found - run: make mantranet-setup\")\n",
    "                return False\n",
    "            \n",
    "            return True\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error checking ManTraNet deps: {e}\")\n",
    "            return False\n",
    "    \n",
    "    def detect(self, image_path: str, context=None) -> DetectionResult:\n",
    "        \"\"\"\n",
    "        Generate forgery mask and analyze for manipulations.\n",
    "        \n",
    "        Returns DetectionResult with:\n",
    "        - mask_id: GridFS ID of saved forgery mask\n",
    "        - manipulated_percentage: % of pixels flagged\n",
    "        - region_count: Number of discrete manipulated regions\n",
    "        - audit_findings: Findings for the auditor\n",
    "        \"\"\"\n",
    "        if not self.check_deps():\n",
    "            return DetectionResult(\n",
    "                method=DetectionMethod.ML_MODEL,\n",
    "                is_ai_generated=None,\n",
    "                confidence=ConfidenceLevel.NONE,\n",
    "                score=0.0,\n",
    "                evidence=\"ManTraNet not available - run: make mantranet-setup\"\n",
    "            )\n",
    "        \n",
    "        try:\n",
    "            # Run inference via subprocess (TF 1.14 environment)\n",
    "            mask, inference_time = self._run_inference(image_path)\n",
    "            \n",
    "            # Analyze mask\n",
    "            analysis = self._analyze_mask(mask)\n",
    "            \n",
    "            # Save mask to GridFS\n",
    "            mask_id = self._save_mask_to_gridfs(mask, context)\n",
    "            \n",
    "            # Create audit findings\n",
    "            findings = self._create_audit_findings(analysis)\n",
    "            \n",
    "            # Determine overall verdict\n",
    "            is_manipulated = analysis['manipulated_percentage'] > 5.0\n",
    "            \n",
    "            return DetectionResult(\n",
    "                method=DetectionMethod.ML_MODEL,\n",
    "                is_ai_generated=False,  # ManTraNet detects editing, not AI generation\n",
    "                confidence=self._calculate_confidence(analysis),\n",
    "                score=analysis['max_confidence'],\n",
    "                evidence=self._format_evidence(analysis, inference_time),\n",
    "                metadata={\n",
    "                    'model': 'ManTraNet',\n",
    "                    'mask_id': mask_id,\n",
    "                    'manipulated_percentage': analysis['manipulated_percentage'],\n",
    "                    'region_count': analysis['region_count'],\n",
    "                    'max_confidence': analysis['max_confidence'],\n",
    "                    'mean_confidence': analysis['mean_confidence'],\n",
    "                    'inference_time_s': round(inference_time, 3),\n",
    "                    'audit_findings': findings,\n",
    "                }\n",
    "            )\n",
    "            \n",
    "        except Exception as e:\n",
    "            logger.error(f\"ManTraNet error: {e}\", exc_info=True)\n",
    "            return DetectionResult(\n",
    "                method=DetectionMethod.ML_MODEL,\n",
    "                is_ai_generated=None,\n",
    "                confidence=ConfidenceLevel.NONE,\n",
    "                score=0.0,\n",
    "                evidence=f\"ManTraNet error: {e}\"\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "936e981f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _analyze_mask(self, mask: np.ndarray) -> dict:\n",
    "    \"\"\"\n",
    "    Analyze forgery mask to extract metrics.\n",
    "    \n",
    "    Returns:\n",
    "        dict with manipulated_percentage, region_count, max_confidence,\n",
    "        mean_confidence, and region_sizes\n",
    "    \"\"\"\n",
    "    import cv2\n",
    "    \n",
    "    # Threshold mask at 0.5 for binary analysis\n",
    "    binary_mask = (mask > 0.5).astype(np.uint8)\n",
    "    \n",
    "    # Calculate manipulated percentage\n",
    "    total_pixels = mask.size\n",
    "    manipulated_pixels = np.sum(binary_mask)\n",
    "    manipulated_percentage = (manipulated_pixels / total_pixels) * 100\n",
    "    \n",
    "    # Find connected components (discrete manipulated regions)\n",
    "    num_regions, labels, stats, centroids = cv2.connectedComponentsWithStats(\n",
    "        binary_mask, connectivity=8\n",
    "    )\n",
    "    \n",
    "    # Region 0 is background, so subtract 1\n",
    "    region_count = num_regions - 1 if num_regions > 0 else 0\n",
    "    \n",
    "    # Get region sizes (excluding background)\n",
    "    region_sizes = stats[1:, cv2.CC_STAT_AREA].tolist() if region_count > 0 else []\n",
    "    \n",
    "    # Confidence statistics (only from manipulated pixels)\n",
    "    manipulated_values = mask[binary_mask == 1]\n",
    "    max_confidence = float(np.max(manipulated_values)) if len(manipulated_values) > 0 else 0.0\n",
    "    mean_confidence = float(np.mean(manipulated_values)) if len(manipulated_values) > 0 else 0.0\n",
    "    \n",
    "    return {\n",
    "        'manipulated_percentage': manipulated_percentage,\n",
    "        'region_count': region_count,\n",
    "        'max_confidence': max_confidence,\n",
    "        'mean_confidence': mean_confidence,\n",
    "        'region_sizes': region_sizes,\n",
    "    }\n",
    "\n",
    "\n",
    "def _create_audit_findings(self, analysis: dict) -> list:\n",
    "    \"\"\"\n",
    "    Create audit findings based on mask analysis.\n",
    "    \n",
    "    Returns list of findings following the plugin contract.\n",
    "    \"\"\"\n",
    "    findings = []\n",
    "    \n",
    "    pct = analysis['manipulated_percentage']\n",
    "    conf = analysis['mean_confidence']\n",
    "    regions = analysis['region_count']\n",
    "    \n",
    "    # HIGH: >20% manipulated with high confidence\n",
    "    if pct > 20 and conf > 0.7:\n",
    "        findings.append({\n",
    "            'level': 'HIGH',\n",
    "            'category': 'Manipulation Localization',\n",
    "            'description': f'Extensive manipulation detected: {pct:.1f}% of image affected in {regions} region(s)',\n",
    "            'is_positive': False,\n",
    "            'confidence': float(conf)\n",
    "        })\n",
    "    \n",
    "    # MEDIUM: 5-20% manipulated or high % with lower confidence\n",
    "    elif (pct > 5 and conf > 0.6) or (pct > 20 and conf > 0.5):\n",
    "        findings.append({\n",
    "            'level': 'MEDIUM',\n",
    "            'category': 'Manipulation Localization',\n",
    "            'description': f'Moderate manipulation detected: {pct:.1f}% of image affected in {regions} region(s)',\n",
    "            'is_positive': False,\n",
    "            'confidence': float(conf)\n",
    "        })\n",
    "    \n",
    "    # LOW: 1-5% manipulated or borderline detection\n",
    "    elif pct > 1:\n",
    "        findings.append({\n",
    "            'level': 'LOW',\n",
    "            'category': 'Manipulation Localization',\n",
    "            'description': f'Minor manipulation detected: {pct:.1f}% of image affected in {regions} region(s)',\n",
    "            'is_positive': False,\n",
    "            'confidence': float(conf)\n",
    "        })\n",
    "    \n",
    "    # Positive finding: clean image\n",
    "    elif pct < 0.5:\n",
    "        findings.append({\n",
    "            'level': 'MEDIUM',\n",
    "            'category': 'Manipulation Localization',\n",
    "            'description': 'No significant manipulation detected by forgery localization',\n",
    "            'is_positive': True,\n",
    "            'confidence': 1.0 - float(conf)\n",
    "        })\n",
    "    \n",
    "    return findings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf5a82cf",
   "metadata": {},
   "source": [
    "### Template\n",
    "\n",
    "Create `templates/analyses/report/forgery.html`:\n",
    "\n",
    "```html\n",
    "{% extends \"analyses/report/report_base.html\" %}\n",
    "\n",
    "{% block report_content %}\n",
    "<div class=\"container-fluid\">\n",
    "    {% if error %}\n",
    "        <div class=\"alert alert-warning\">{{ error }}</div>\n",
    "    {% elif mantranet.enabled %}\n",
    "        <div class=\"row mb-4\">\n",
    "            <div class=\"col-12\">\n",
    "                <h3><i class=\"fa-solid fa-crosshairs me-2\"></i>Manipulation Localization</h3>\n",
    "                <p class=\"text-muted\">\n",
    "                    ManTraNet forgery detection highlights manipulated regions in red.\n",
    "                    Darker red indicates higher confidence of manipulation.\n",
    "                </p>\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"row mb-4\">\n",
    "            <div class=\"col-md-6\">\n",
    "                <h5>Original Image</h5>\n",
    "                <img src=\"{% url 'object_get' pk=analysis.image_id %}\" \n",
    "                     class=\"img-fluid border\" \n",
    "                     alt=\"Original\">\n",
    "            </div>\n",
    "            <div class=\"col-md-6\">\n",
    "                <h5>Forgery Mask</h5>\n",
    "                {% if mantranet.mask_id %}\n",
    "                    <img src=\"{% url 'object_get' pk=mantranet.mask_id %}\" \n",
    "                         class=\"img-fluid border\" \n",
    "                         alt=\"Forgery Mask\">\n",
    "                {% else %}\n",
    "                    <div class=\"alert alert-info\">No forgery mask generated</div>\n",
    "                {% endif %}\n",
    "            </div>\n",
    "        </div>\n",
    "        \n",
    "        <div class=\"row\">\n",
    "            <div class=\"col-12\">\n",
    "                <div class=\"card\">\n",
    "                    <div class=\"card-header\"><strong>Detection Results</strong></div>\n",
    "                    <div class=\"card-body\">\n",
    "                        <table class=\"table table-sm\">\n",
    "                            <tr>\n",
    "                                <td><strong>Manipulated Area:</strong></td>\n",
    "                                <td>{{ mantranet.manipulated_percentage|floatformat:2 }}%</td>\n",
    "                            </tr>\n",
    "                            <tr>\n",
    "                                <td><strong>Number of Regions:</strong></td>\n",
    "                                <td>{{ mantranet.region_count }}</td>\n",
    "                            </tr>\n",
    "                            <tr>\n",
    "                                <td><strong>Max Confidence:</strong></td>\n",
    "                                <td>{{ mantranet.max_confidence|floatformat:3 }}</td>\n",
    "                            </tr>\n",
    "                            <tr>\n",
    "                                <td><strong>Mean Confidence:</strong></td>\n",
    "                                <td>{{ mantranet.mean_confidence|floatformat:3 }}</td>\n",
    "                            </tr>\n",
    "                        </table>\n",
    "                    </div>\n",
    "                </div>\n",
    "            </div>\n",
    "        </div>\n",
    "    {% endif %}\n",
    "</div>\n",
    "{% endblock %}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73760ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example inference code from Colab\n",
    "import numpy as np\n",
    "import cv2\n",
    "from datetime import datetime\n",
    "\n",
    "def read_rgb_image(image_file):\n",
    "    \"\"\"Load image as RGB.\"\"\"\n",
    "    rgb = cv2.imread(image_file, 1)[..., ::-1]\n",
    "    return rgb\n",
    "\n",
    "def decode_an_image_array(rgb, manTraNet, dn=1):\n",
    "    \"\"\"\n",
    "    Run ManTraNet inference on RGB image.\n",
    "    \n",
    "    Args:\n",
    "        rgb: RGB numpy array\n",
    "        manTraNet: Loaded model\n",
    "        dn: Downsample factor (1=full res, 2=half res, etc.)\n",
    "        \n",
    "    Returns:\n",
    "        mask: Forgery probability mask (H×W, values 0-1)\n",
    "        time: Inference time\n",
    "    \"\"\"\n",
    "    # Normalize to [-1, 1]\n",
    "    x = np.expand_dims(rgb.astype('float32') / 255.0 * 2 - 1, axis=0)\n",
    "    \n",
    "    # Optional downsampling for speed\n",
    "    x = x[:, ::dn, ::dn]\n",
    "    \n",
    "    # Inference\n",
    "    t0 = datetime.now()\n",
    "    y = manTraNet.predict(x)[0, ..., 0]\n",
    "    t1 = datetime.now()\n",
    "    \n",
    "    return y, t1 - t0\n",
    "\n",
    "def decode_an_image_file(image_file, manTraNet, dn=1):\n",
    "    \"\"\"Load image from file and run inference.\"\"\"\n",
    "    rgb = read_rgb_image(image_file)\n",
    "    return decode_an_image_array(rgb, manTraNet, dn)\n",
    "\n",
    "\n",
    "# Example usage:\n",
    "# mask, inference_time = decode_an_image_file('suspicious.jpg', manTraNet, dn=1)\n",
    "# print(f\"Inference took {inference_time}\")\n",
    "# print(f\"Mask shape: {mask.shape}, values range: [{mask.min():.3f}, {mask.max():.3f}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0233b9d7",
   "metadata": {},
   "source": [
    "## 8. Example Audit Finding Scenarios\n",
    "\n",
    "### Scenario 1: Major Manipulation\n",
    "\n",
    "```python\n",
    "# 25% of image manipulated, high confidence\n",
    "analysis = {\n",
    "    'manipulated_percentage': 25.3,\n",
    "    'mean_confidence': 0.82,\n",
    "    'region_count': 3\n",
    "}\n",
    "\n",
    "findings = [\n",
    "    {\n",
    "        'level': 'HIGH',  # 50 points subtracted\n",
    "        'category': 'Manipulation Localization',\n",
    "        'description': 'Extensive manipulation detected: 25.3% of image affected in 3 region(s)',\n",
    "        'is_positive': False,\n",
    "        'confidence': 0.82\n",
    "    }\n",
    "]\n",
    "\n",
    "# Auditor impact: Base 50 - 50 (HIGH) = 0 (definitely fake)\n",
    "```\n",
    "\n",
    "### Scenario 2: Moderate Editing\n",
    "\n",
    "```python\n",
    "# 8% manipulated, moderate confidence\n",
    "analysis = {\n",
    "    'manipulated_percentage': 8.1,\n",
    "    'mean_confidence': 0.65,\n",
    "    'region_count': 1\n",
    "}\n",
    "\n",
    "findings = [\n",
    "    {\n",
    "        'level': 'MEDIUM',  # 15 points subtracted\n",
    "        'category': 'Manipulation Localization',\n",
    "        'description': 'Moderate manipulation detected: 8.1% of image affected in 1 region(s)',\n",
    "        'is_positive': False,\n",
    "        'confidence': 0.65\n",
    "    }\n",
    "]\n",
    "\n",
    "# Auditor impact: Base 50 - 15 (MEDIUM) = 35 (likely fake)\n",
    "```\n",
    "\n",
    "### Scenario 3: Clean Image\n",
    "\n",
    "```python\n",
    "# <0.5% manipulated (essentially clean)\n",
    "analysis = {\n",
    "    'manipulated_percentage': 0.3,\n",
    "    'mean_confidence': 0.15,\n",
    "    'region_count': 0\n",
    "}\n",
    "\n",
    "findings = [\n",
    "    {\n",
    "        'level': 'MEDIUM',  # 15 points added\n",
    "        'category': 'Manipulation Localization',\n",
    "        'description': 'No significant manipulation detected by forgery localization',\n",
    "        'is_positive': True,\n",
    "        'confidence': 0.85\n",
    "    }\n",
    "]\n",
    "\n",
    "# Auditor impact: Base 50 + 15 (MEDIUM positive) = 65 (likely real)\n",
    "```\n",
    "\n",
    "## Next Steps\n",
    "\n",
    "1. ✅ Review this notebook for accuracy\n",
    "2. ⏳ Create ManTraNetDetector plugin\n",
    "3. ⏳ Setup TF 1.14 environment and download model\n",
    "4. ⏳ Add UI tab and views\n",
    "5. ⏳ Test on sample images\n",
    "6. ⏳ Integrate with auditor scoring\n",
    "7. ⏳ Document in README"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc1f046",
   "metadata": {},
   "source": [
    "## 7. Implementation Summary\n",
    "\n",
    "### Files to Create\n",
    "\n",
    "1. **`ai_detection/detectors/mantranet_detector.py`**\n",
    "   - ManTraNetDetector class\n",
    "   - Mask analysis logic\n",
    "   - Audit findings generation\n",
    "   - GridFS mask storage\n",
    "\n",
    "2. **`ai_detection/mantranet_infer.py`**\n",
    "   - Standalone inference script (TF 1.14 environment)\n",
    "   - Called via subprocess from detector\n",
    "   - Returns mask as JSON/NPY\n",
    "\n",
    "3. **`templates/analyses/report/forgery.html`**\n",
    "   - New tab template\n",
    "   - Side-by-side original + mask display\n",
    "   - Detection statistics table\n",
    "\n",
    "4. **`ai_detection/Makefile`** updates\n",
    "   - `make mantranet-setup`: Download model and setup TF 1.14 venv\n",
    "   - `make mantranet-test`: Test inference\n",
    "\n",
    "### Files to Modify\n",
    "\n",
    "1. **`analyses/urls.py`**\n",
    "   - Add `show_forgery` route\n",
    "\n",
    "2. **`analyses/views.py`**\n",
    "   - Add `show_forgery()` view function\n",
    "\n",
    "3. **`templates/analyses/report/report_base.html`**\n",
    "   - Add \"Forgery Localization\" tab to navigation\n",
    "\n",
    "4. **`ai_detection/detectors/__init__.py`**\n",
    "   - Import and register ManTraNetDetector\n",
    "\n",
    "### Setup Commands\n",
    "\n",
    "```bash\n",
    "cd ai_detection/\n",
    "make mantranet-setup   # Download ManTraNet repo and model\n",
    "make mantranet-test    # Test inference on sample images\n",
    "```\n",
    "\n",
    "### Integration Flow\n",
    "\n",
    "```\n",
    "User uploads image\n",
    "    ↓\n",
    "Processing pipeline runs all plugins\n",
    "    ↓\n",
    "ManTraNetDetector.detect() called\n",
    "    ↓\n",
    "Runs inference via subprocess (TF 1.14 venv)\n",
    "    ↓\n",
    "Analyzes mask → creates audit_findings\n",
    "    ↓\n",
    "Saves mask to GridFS\n",
    "    ↓\n",
    "Auditor reads audit_findings\n",
    "    ↓\n",
    "Adds/subtracts points based on findings\n",
    "    ↓\n",
    "Final authenticity score calculated\n",
    "    ↓\n",
    "User views \"Forgery Localization\" tab\n",
    "    ↓\n",
    "Displays mask highlighting manipulated regions\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e8cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "from PIL import Image\n",
    "import io\n",
    "\n",
    "def mask_to_heatmap_image(mask, colormap='hot'):\n",
    "    \"\"\"\n",
    "    Convert forgery mask to colored heatmap image.\n",
    "    \n",
    "    Args:\n",
    "        mask: numpy array (H×W) with values 0-1\n",
    "        colormap: matplotlib colormap name ('hot', 'jet', 'magma', etc.)\n",
    "        \n",
    "    Returns:\n",
    "        PIL Image (RGB) of the heatmap\n",
    "    \"\"\"\n",
    "    # Normalize to 0-255\n",
    "    mask_normalized = (mask * 255).astype(np.uint8)\n",
    "    \n",
    "    # Apply colormap\n",
    "    cmap = cm.get_cmap(colormap)\n",
    "    colored = cmap(mask_normalized)\n",
    "    \n",
    "    # Convert to RGB (drop alpha channel)\n",
    "    rgb = (colored[:, :, :3] * 255).astype(np.uint8)\n",
    "    \n",
    "    # Convert to PIL Image\n",
    "    img = Image.fromarray(rgb)\n",
    "    return img\n",
    "\n",
    "def save_mask_to_bytes(mask, format='PNG'):\n",
    "    \"\"\"Save mask as image bytes for storage.\"\"\"\n",
    "    img = mask_to_heatmap_image(mask)\n",
    "    buffer = io.BytesIO()\n",
    "    img.save(buffer, format=format)\n",
    "    buffer.seek(0)\n",
    "    return buffer.getvalue()\n",
    "\n",
    "\n",
    "# Example visualization\n",
    "# from matplotlib import pyplot as plt\n",
    "# \n",
    "# fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "# \n",
    "# # Original image\n",
    "# axes[0].imshow(original_rgb)\n",
    "# axes[0].set_title('Original Image')\n",
    "# axes[0].axis('off')\n",
    "# \n",
    "# # Forgery mask\n",
    "# im = axes[1].imshow(mask, cmap='hot', vmin=0, vmax=1)\n",
    "# axes[1].set_title('Forgery Mask (Red = Manipulated)')\n",
    "# axes[1].axis('off')\n",
    "# plt.colorbar(im, ax=axes[1])\n",
    "# \n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64c1278",
   "metadata": {},
   "source": [
    "## 6. Mask Visualization\n",
    "\n",
    "Convert the mask to a heatmap image for display:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550f3310",
   "metadata": {},
   "source": [
    "## 5. Example ManTraNet Inference Code\n",
    "\n",
    "Based on the Colab notebook, here's how ManTraNet runs inference:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe222a4c",
   "metadata": {},
   "source": [
    "### Update Tab Navigation\n",
    "\n",
    "Add to `templates/analyses/report/report_base.html` navigation:\n",
    "\n",
    "```html\n",
    "{% if analysis.report.mantranet_localization.enabled %}\n",
    "<li class=\"nav-item\">\n",
    "    <a class=\"nav-link {% if active_tab == 'forgery' %}active{% endif %}\" \n",
    "       href=\"{% url 'show_forgery' analysis.id %}\">\n",
    "        <i class=\"fa-solid fa-crosshairs\"></i> Forgery Localization\n",
    "    </a>\n",
    "</li>\n",
    "{% endif %}\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0203725a",
   "metadata": {},
   "outputs": [],
   "source": [
    "@require_safe\n",
    "@login_required\n",
    "def show_forgery(request, analysis_id):\n",
    "    \"\"\"Shows forgery localization report (ManTraNet mask).\"\"\"\n",
    "    context, error_response = _get_completed_analysis(request, analysis_id)\n",
    "    if error_response:\n",
    "        return error_response\n",
    "    \n",
    "    # Check if ManTraNet results exist\n",
    "    mantranet_data = context['analysis'].report.get('mantranet_localization', {})\n",
    "    \n",
    "    if not mantranet_data.get('enabled'):\n",
    "        context['error'] = 'Forgery localization not available for this image'\n",
    "    \n",
    "    context['active_tab'] = 'forgery'\n",
    "    context['mantranet'] = mantranet_data\n",
    "    \n",
    "    return render(request, \"analyses/report/forgery.html\", context)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f690bb4",
   "metadata": {},
   "source": [
    "## 4. UI Integration — Forgery Localization Tab\n",
    "\n",
    "Add a new tab to display the forgery mask:\n",
    "\n",
    "### URL Route\n",
    "\n",
    "Add to `analyses/urls.py`:\n",
    "```python\n",
    "re_path(r\"^show/(?P<analysis_id>[\\d]+)/forgery/$\", views.show_forgery, name=\"show_forgery\"),\n",
    "```\n",
    "\n",
    "### View Function\n",
    "\n",
    "Add to `analyses/views.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282007d7",
   "metadata": {},
   "source": [
    "### Mask Analysis and Finding Creation\n",
    "\n",
    "The detector analyzes the forgery mask to create audit findings:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e377037b",
   "metadata": {},
   "source": [
    "## 3. Detector Plugin Implementation\n",
    "\n",
    "Create `ai_detection/detectors/mantranet_detector.py`:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce4da80b",
   "metadata": {},
   "source": [
    "## 1. Plugin Contract Review\n",
    "\n",
    "### Audit Findings Contract\n",
    "\n",
    "Plugins communicate with the auditor via `audit_findings` in their results dictionary:\n",
    "\n",
    "```python\n",
    "results['plugin_name'] = {\n",
    "    'audit_findings': [\n",
    "        {\n",
    "            'level': 'HIGH',  # LOW, MEDIUM, or HIGH\n",
    "            'category': 'Manipulation Detection',\n",
    "            'description': 'Copy-move forgery detected in 15.2% of image',\n",
    "            'is_positive': False,  # False = evidence of fakery\n",
    "            'confidence': 0.85  # Optional: 0.0-1.0\n",
    "        }\n",
    "    ],\n",
    "    # ... other plugin-specific data\n",
    "}\n",
    "```\n",
    "\n",
    "### Auditor Scoring System\n",
    "\n",
    "- **Points**: LOW=5, MEDIUM=15, HIGH=50\n",
    "- **Base Score**: 50 (uncertain)\n",
    "- **Positive findings**: Add points (evidence of authenticity)\n",
    "- **Negative findings**: Subtract points (evidence of manipulation)\n",
    "- **Final Score**: Clamped to 0-100\n",
    "\n",
    "### When to Use Each Level\n",
    "\n",
    "- **HIGH**: Virtual certainty (>90% confidence) - e.g., >20% of image manipulated with high confidence\n",
    "- **MEDIUM**: Strong evidence (70-90% confidence) - e.g., 5-20% manipulated or lower confidence\n",
    "- **LOW**: Weak signal (50-70% confidence) - e.g., <5% manipulated or borderline detection"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
