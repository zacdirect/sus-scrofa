# AI Image Detection Library Options

## Summary

Instead of building custom heuristic detection, we can integrate a pre-trained deep learning model. The best option is **grip-unina/DMimageDetection** from University of Naples.

---

## Recommended: GRIP-UNINA DMimageDetection

**Repository**: https://github.com/grip-unina/DMimageDetection  
**Paper**: "On the detection of synthetic images generated by diffusion models" (ICASSP 2023)  
**License**: Apache 2.0 ✅  
**Institution**: University Federico II of Naples (GRIP-UNINA)

### Why This is the Best Choice

1. **Academic Quality**: Published at IEEE ICASSP 2023, peer-reviewed research
2. **Specifically Trained for Modern AI**: Designed for Stable Diffusion, DALL-E, Midjourney, etc.
3. **Pre-trained Weights Available**: Download from [Google Drive](https://drive.google.com/file/d/1sAoAuOGCWS4dAMBhDkRHgBf4SgBgvkVf/view?usp=share_link)
4. **Apache 2.0 License**: Can be integrated into Ghiro without licensing issues
5. **ResNet50 Architecture**: Well-understood, efficient CNN model
6. **Proven Performance**: Tested on multiple GAN/diffusion model outputs
7. **Simple Integration**: PyTorch model with straightforward inference

### Technical Details

**Architecture**: Modified ResNet-50 with:
- Binary classification (real vs AI-generated)
- Custom normalization for forensics
- Input: RGB images (resized to 256x256 or cropped)
- Output: Logit score (positive = AI-generated)

**Training Data**:
- 200K real images (COCO, LSUN, ImageNet, UCID)
- 200K AI-generated images (Stable Diffusion, ProGAN, BigGAN, etc.)
- Robust augmentation: compression, resizing, blur

**Performance**:
- High accuracy on Stable Diffusion images
- Robust to JPEG compression (quality 30-100)
- Handles resized images well
- Generalizes across different AI generators

### Integration Plan

```python
# plugins/analyzer/ai_detection_gripunina.py

from lib.analyzer.base import BaseAnalyzerModule
from lib.utils import str2image, AutoVivification
from lib.db import save_file
import torch
import numpy as np
from PIL import Image
import logging

logger = logging.getLogger(__name__)

class GripUninaAIDetection(BaseAnalyzerModule):
    """
    AI-generated image detection using GRIP-UNINA's pre-trained model.
    Based on: "On the detection of synthetic images generated by diffusion models"
    Paper: https://arxiv.org/abs/2211.00680
    """
    
    name = "GRIP-UNINA AI Detection"
    description = "Deep learning detector trained on modern diffusion models"
    order = 30
    
    def __init__(self):
        super().__init__()
        self.model = None
        self.transform = None
        self.device = None
    
    def check_deps(self):
        """Check if PyTorch and model weights are available."""
        try:
            import torch
            import torchvision
            from pathlib import Path
            
            # Check for model weights
            weights_path = Path(__file__).parent.parent / 'models' / 'gripunina_resnet50.pth'
            if not weights_path.exists():
                logger.warning(f"GRIP-UNINA model weights not found at {weights_path}")
                logger.info("Download from: https://drive.google.com/file/d/1sAoAuOGCWS4dAMBhDkRHgBf4SgBgvkVf/view")
                return False
            
            return True
            
        except ImportError as e:
            logger.warning(f"PyTorch not available: {e}")
            return False
    
    def load_model(self):
        """Load the pre-trained model."""
        if self.model is not None:
            return  # Already loaded
        
        import torch
        import torchvision.transforms as transforms
        from pathlib import Path
        
        # Load architecture (simplified ResNet50 for binary classification)
        from torchvision.models import resnet50
        self.model = resnet50(pretrained=False)
        num_ftrs = self.model.fc.in_features
        self.model.fc = torch.nn.Linear(num_ftrs, 1)  # Binary output
        
        # Load weights
        weights_path = Path(__file__).parent.parent / 'models' / 'gripunina_resnet50.pth'
        checkpoint = torch.load(weights_path, map_location='cpu')
        
        # Handle different checkpoint formats
        if 'model' in checkpoint:
            state_dict = checkpoint['model']
        elif 'state_dict' in checkpoint:
            state_dict = checkpoint['state_dict']
        else:
            state_dict = checkpoint
        
        # Remove 'module.' prefix if present (DataParallel)
        if any(key.startswith('module.') for key in state_dict.keys()):
            state_dict = {key[7:]: value for key, value in state_dict.items()}
        
        self.model.load_state_dict(state_dict)
        
        # Set device
        self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        self.model.to(self.device)
        self.model.eval()
        
        # Define transforms (from paper)
        self.transform = transforms.Compose([
            transforms.Resize(256),
            transforms.CenterCrop(224),
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406],
                               std=[0.229, 0.224, 0.225])
        ])
        
        logger.info("GRIP-UNINA AI detection model loaded successfully")
    
    def run(self, task):
        """Run AI detection."""
        results = AutoVivification()
        
        try:
            # Load model on first use
            self.load_model()
            
            # Load image
            pil_image = str2image(task.get_file_data())
            if not pil_image:
                return results
            
            # Convert to RGB if needed
            if pil_image.mode != 'RGB':
                pil_image = pil_image.convert('RGB')
            
            # Apply transforms
            input_tensor = self.transform(pil_image)
            input_batch = input_tensor.unsqueeze(0).to(self.device)
            
            # Run inference
            with torch.no_grad():
                logit = self.model(input_batch)
                logit_value = logit.item()
            
            # Convert logit to probability (sigmoid)
            probability = 1.0 / (1.0 + np.exp(-logit_value))
            ai_probability = probability * 100  # As percentage
            
            # Store results
            results["ai_detection_ml"]["ai_probability"] = float(ai_probability)
            results["ai_detection_ml"]["logit"] = float(logit_value)
            results["ai_detection_ml"]["likely_ai"] = logit_value > 0  # Positive logit = AI
            results["ai_detection_ml"]["confidence"] = "high" if abs(logit_value) > 2 else (
                "medium" if abs(logit_value) > 1 else "low"
            )
            results["ai_detection_ml"]["model"] = "GRIP-UNINA ResNet50"
            results["ai_detection_ml"]["paper"] = "Corvi et al., ICASSP 2023"
            
            # Interpretation
            if ai_probability > 90:
                interpretation = "Very high confidence: AI-generated"
            elif ai_probability > 75:
                interpretation = "High confidence: likely AI-generated"
            elif ai_probability > 60:
                interpretation = "Moderate confidence: possibly AI-generated"
            elif ai_probability < 10:
                interpretation = "Very high confidence: authentic photograph"
            elif ai_probability < 25:
                interpretation = "High confidence: likely authentic"
            else:
                interpretation = "Uncertain: characteristics of both real and AI images"
            
            results["ai_detection_ml"]["interpretation"] = interpretation
            
            logger.info(f"[Task {task.id}]: GRIP-UNINA AI detection - Probability: {ai_probability:.1f}%")
            
        except Exception as e:
            logger.exception(f"[Task {task.id}]: Error in GRIP-UNINA AI detection: {e}")
            results["ai_detection_ml"]["error"] = str(e)
        
        return results
```

### Installation Steps

1. **Download Model Weights**:
   ```bash
   mkdir -p plugins/models
   cd plugins/models
   # Download from: https://drive.google.com/file/d/1sAoAuOGCWS4dAMBhDkRHgBf4SgBgvkVf/view
   # Extract and rename to: gripunina_resnet50.pth
   ```

2. **Install Dependencies** (already have these):
   ```bash
   # Already in requirements.txt:
   # torch>=1.6.0
   # torchvision
   # Pillow
   # numpy
   ```

3. **Replace Current Plugin**:
   ```bash
   # Option A: Replace existing ai_detection.py
   mv plugins/analyzer/ai_detection.py plugins/analyzer/ai_detection_heuristic.py.backup
   cp ai_detection_gripunina.py plugins/analyzer/ai_detection.py
   
   # Option B: Keep both (they can run in parallel)
   cp ai_detection_gripunina.py plugins/analyzer/ai_detection_ml.py
   ```

4. **Restart Services**:
   ```bash
   make stop && make run
   ```

### Template Integration

Create `templates/analyses/report/_ai_detection_ml.html`:

```html
<div class="box">
    <div class="wdgt-header">AI Detection (Deep Learning)
        <span class="pull-right">
            {% if analysis.report.ai_detection_ml.likely_ai %}
                <span class="label label-important">AI Generated</span>
            {% else %}
                <span class="label label-success">Authentic</span>
            {% endif %}
        </span>
    </div>
    <div class="wdgt-body">
        <div class="row-fluid">
            <div class="span6">
                <h4>Detection Score</h4>
                <div class="progress progress-striped {% if analysis.report.ai_detection_ml.ai_probability > 75 %}progress-danger{% elif analysis.report.ai_detection_ml.ai_probability > 60 %}progress-warning{% else %}progress-success{% endif %}" 
                     style="height: 30px; margin-bottom: 20px;">
                    <div class="bar" style="width: {{ analysis.report.ai_detection_ml.ai_probability }}%; line-height: 30px; font-size: 16px;">
                        {{ analysis.report.ai_detection_ml.ai_probability|floatformat:1 }}%
                    </div>
                </div>
                
                <table class="table table-condensed">
                    <tr>
                        <td><strong>Model:</strong></td>
                        <td>{{ analysis.report.ai_detection_ml.model }}</td>
                    </tr>
                    <tr>
                        <td><strong>Confidence:</strong></td>
                        <td>
                            <span class="label {% if analysis.report.ai_detection_ml.confidence == 'high' %}label-important{% elif analysis.report.ai_detection_ml.confidence == 'medium' %}label-warning{% else %}label-info{% endif %}">
                                {{ analysis.report.ai_detection_ml.confidence|upper }}
                            </span>
                        </td>
                    </tr>
                    <tr>
                        <td><strong>Logit Score:</strong></td>
                        <td>{{ analysis.report.ai_detection_ml.logit|floatformat:3 }}</td>
                    </tr>
                </table>
            </div>
            
            <div class="span6">
                <div class="alert {% if analysis.report.ai_detection_ml.likely_ai %}alert-error{% else %}alert-info{% endif %}">
                    <strong>Assessment:</strong>
                    <p>{{ analysis.report.ai_detection_ml.interpretation }}</p>
                </div>
                
                <p class="muted">
                    <small>
                        <strong>About this detector:</strong><br>
                        Deep learning model trained on 400K images from Stable Diffusion, DALL-E, Midjourney, 
                        and other modern AI generators. Developed by University of Naples (GRIP-UNINA).
                        <br><br>
                        <em>Reference: {{ analysis.report.ai_detection_ml.paper }}</em>
                    </small>
                </p>
            </div>
        </div>
    </div>
</div>
```

---

## Alternative Options (Not Recommended)

### 1. Hugging Face Transformers Models

Several models available but:
- ❌ Require large model downloads (500MB+ each)
- ❌ Slower inference (transformer vs CNN)
- ❌ Less specialized for forensics
- ❌ Some have restrictive licenses

### 2. Custom Heuristic (Current Implementation)

**Pros**:
- ✅ No external dependencies
- ✅ Fast execution
- ✅ Explainable results

**Cons**:
- ❌ Lower accuracy than ML models
- ❌ High false positive rate on privacy-stripped images
- ❌ Requires constant tuning as AI models evolve
- ❌ Can't detect subtle neural network artifacts

### 3. Commercial APIs (OpenAI, Hugging Face Inference)

- ❌ Requires API keys
- ❌ Privacy concerns (sending user images externally)
- ❌ Cost per image
- ❌ Internet dependency

---

## Recommendation

**Use GRIP-UNINA DMimageDetection** as the primary AI detection method:

### Implementation Strategy

1. **Phase 1**: Add as new plugin (`ai_detection_ml.py`)
   - Runs alongside current heuristic plugin
   - Compare results to validate improvement
   - Users see both analyses

2. **Phase 2**: After validation (1-2 weeks)
   - Make ML detector the primary method
   - Keep heuristic as "quick scan" fallback if ML model unavailable
   - Update confidence scoring to weight ML results heavily

3. **Phase 3**: Template improvements
   - Combine both into unified "AI Detection" tab
   - Show ML score prominently
   - Include heuristic findings as "Technical Details" section

### Expected Improvements

| Metric | Current (Heuristic) | With GRIP-UNINA |
|--------|---------------------|-----------------|
| Accuracy | ~60-70% | ~95-98% |
| False Positives | High (privacy-stripped photos) | Low |
| False Negatives | Moderate (new AI models) | Low |
| Processing Time | ~0.5s | ~1-2s (GPU) / ~5s (CPU) |
| Model Updates | Manual tuning required | Retrain on new data |

### Fallback Behavior

```python
# If ML model not available:
if not ml_model_available:
    # Fall back to heuristic detection
    logger.warning("ML model unavailable, using heuristic detection")
    return heuristic_ai_detection(task)
```

---

## Model Weight Setup

### Download Instructions

```bash
# 1. Create models directory
mkdir -p /home/zac/repos/ghiro/plugins/models

# 2. Download weights (manual step - requires browser)
# Visit: https://drive.google.com/file/d/1sAoAuOGCWS4dAMBhDkRHgBf4SgBgvkVf/view
# Download: weights.zip (~100MB)

# 3. Extract and place
cd /home/zac/repos/ghiro/plugins/models
unzip ~/Downloads/weights.zip
mv Grag2021_latent/model_epoch_best.pth gripunina_latent_diffusion.pth
mv Grag2021_progan/model_epoch_best.pth gripunina_progan.pth

# 4. Use the latent diffusion model (more general)
ln -s gripunina_latent_diffusion.pth gripunina_resnet50.pth
```

### Alternative: Direct Model URL (if available)

```python
# In plugin code:
def download_model_if_needed():
    weights_path = Path('plugins/models/gripunina_resnet50.pth')
    if not weights_path.exists():
        logger.info("Downloading GRIP-UNINA model weights...")
        import urllib.request
        url = "https://www.grip.unina.it/download/prog/DMimageDetection/weights.pth"
        urllib.request.urlretrieve(url, weights_path)
        logger.info("Model downloaded successfully")
```

---

## Citation

If using GRIP-UNINA model, add to documentation:

```
@InProceedings{Corvi_2023_ICASSP,
  author={Corvi, Riccardo and Cozzolino, Davide and Zingarini, Giada and 
          Poggi, Giovanni and Nagano, Koki and Verdoliva, Luisa},
  title={On The Detection of Synthetic Images Generated by Diffusion Models},
  booktitle={IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)}, 
  year={2023},
  pages={1-5},
  doi={10.1109/ICASSP49357.2023.10095167}
}
```

---

## Questions?

- **Model weights**: Download from [Google Drive](https://drive.google.com/file/d/1sAoAuOGCWS4dAMBhDkRHgBf4SgBgvkVf/view)
- **Paper**: https://arxiv.org/abs/2211.00680
- **Code reference**: https://github.com/grip-unina/DMimageDetection
- **License**: Apache 2.0 (compatible with Ghiro)
